# 통계학 5주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_5th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

5주차는 `2부. 데이터 분석 준비하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_5th_TIL

### 2부. 데이터 분석 준비하기
### 11.데이터 전처리와 파생변수 생성



## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|----------------|----------|
|1주차| 1부 p.2~56     | ✅      |
|2주차| 1부 p.57~79    | ✅      | 
|3주차| 2부 p.82~120   | ✅      | 
|4주차| 2부 p.121~202  | ✅      | 
|5주차| 2부 p.203~254  | ✅      | 
|6주차| 3부 p.300~356  | 🍽️      | 
|7주차| 3부 p.357~615  | 🍽️      | 

<!-- 여기까진 그대로 둬 주세요-->

# 11.데이터 전처리와 파생변수 생성

```
✅ 학습 목표 :
* 결측값과 이상치를 식별하고 적절한 방법으로 처리할 수 있다.
* 데이터 변환과 가공 기법을 학습하고 활용할 수 있다.
* 모델 성능 향상을 위한 파생 변수를 생성하고 활용할 수 있다.
```


## 11.1. 결측값 처리
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요. -->
### 결측치(missing value)의 종류
1. 완전 무작위 결측(MCAR: Missing Completely at Random): 순수하게 결측값이 무작위로 발생한 경우. 이 경우, 결측값을 포함한 데이터를 제거해도 편향(bias)이 거의 발생되지 않음
2. 무작위 결측(MAR: Missing at Random): 다른 변수의 특성에 의해 해당 변수의 결측치가 체계적으로 발생한 경우 (ex. A마트의 전국 체인 매출 정보 중, 특정 체인점의 POS기기에 오류가 나서 해당 체인점에 해당하는 매출 정보에 결측값이 많이 나타난 경우)
3. 비무작위 결측(NMAR: Missing at Not Random): 결측값들이 해당 변수 자체의 특성을 갖고 있는 경우 (ex. A마트의 고객정보 데이터에서 '고객 소득' 변수에서 결측값들 대부분이 소득이 적어서 소득을 공개하기 꺼려해서 결측이 발생한 경우)

### 결측치 처리 방법
1. 완전 무작위 결측일 경우
- 표본 제거 방법: 결측값이 심하게 많은 변수를 제거하거나, 결측값이 포함된 행을 제외하고 데이터 분석을 하는 방법. 전체 데이터에서 결측값 비율이 10% 미만일 경우, 이 방법을 많이 사용함
- 평균 대치법: 결측값을 제외한 온전한 값들의 평균을 구한 다음, 그 평균 값을 결측값들에 대치하는 것. 그러나 이로 인해 통계량의 표준오차가 왜곡되어 축소되어 나타나고, p-value가 부정확하게 됨
2. 데이터가 시계열적 특성일 경우
- 보간법(interpolation): 단순하게 평균값으로 대치
    - 단순 순서 보간법
    - 시점 고려 보간법
- 회귀 대치법(regression imputation): 해당 변수와 다른 변수 사이의 관계성을 고려하여 결측값을 계산 (ex. '연령' 변수의 결측값을 대치하기 위해 '연 수입' 변수를 사용하는 것). 그러나 결측된 변수의 분산을 과소 추정하는 문제가 있음
- 확률적 회귀대치법(stochastic regression imputation): 표준오차 과소 추정 문제를 해결하기 위해 인위적으로 회귀식에 확률 오차항을 추가하는 방식
- 대중 대치법(multiple imputation): 단순 대치를 여러 번 수행하여 n개의 가상적 데이터를 생상하여 이들의 평균으로 결측값을 대치하는 방법
    - 대치 단계
    - 분석 단계
    - 결합 단계

## 11.2. 이상치 처리
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요. -->

- 이상치: 일부 관측치의 값이 전체 데이터의 범위에서 크게 벗어난 아주 작거나 큰 근단적인 값
### 이상치 처리 방법
1. 이상치 제거(trimming): 추정치의 분산은 감소하지만, 실젯값을 과장하여 편향을 발생시킴
2. 관측값 변경(value modification): 하한 값과 상한 값을 결정한 후 하한 값보다 작으면 하한 값으로 대체하고 상한 값보다 크면 상한 값으로 대체
3. 가중치 조정(weight modification): 이상치의 영향을 감소시키는 가중치를 부여
### 이상치 처리시 유의할 점
- 효과적인 이상치 탐색을 위해서는 해당 데이터 변수들의 의미와 비즈니스 도메인을 먼저 이해하고, 이상치가 생긴 원인을 논리적으로 생각하여 데이터를 바라봐야 함
- 분석 도메인에 따라 이상치가 중요한 분석 요인일 수 있음 (ex. 제품의 불량 원인을 찾아내기 위해 특정 공정의 센서 데이터 변화를 분석하는 경우 → 이상치가 분석의 중요한 요소가 됨)

![](https://github.com/bird-one-00/25-1_STATISTICS_Assignment/blob/main/img/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202025-02-10%20170122.png)

## 11.3. 변수 구간화
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요. -->

- 변수 구간화(Binning): 데이터 분석의 성능을 향상시키기 위해서, 혹은 해석의 편리성을 위해 이산형 변수를 범주형 변수로 변환하는 것
- 목적: 이산형 변수를 범주형 변수로 비즈니스적 상황에 맞도록 변환시킴으로써 데이터의 해석이나 예측, 분류 모델을 의도에 맞도록 유도하는 것
### 변수 구간화 방법
1. 평활화(smoothing): 변수의 값을 일정한 폭이나 빈도로 구간을 나눈 후, 각 구간 안에 속한 데이터의 값을 평균, 중앙값, 경곗값 등으로 변환해주는 것
2. 클러스터링(머신러닝 기법1): 타깃 변수 설정이 필요 없이 구간화할 변수의 값들을 유사한 수준끼리 그룹화
3. 의사결정나무(머신러닝 기법2): 타깃 변수를 설정해, 구간화할 변수의 값을 타깃 변수 예측에 가장 적합한 구간으로 나누어줌

## 11.4. 데이터 표준화와 정규화 스케일링
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요. -->

- 표준화, 정규화의 중요성: 표준화와 정규화는 거리를 활용한 군집 분석(k-Nearest Neighbor, 서포트 벡터 머신)에서 필수적임
1. 표준화(Z-score): 각 관측치의 값이 전체 평균을 기준으로 어느 정도 떨어져 있는지 나타낼 때 사용. 평균은 0으로 변환, 1 표준편차 거리는 ±1, 2 표준편차 거리는 ±2로 변환
2. 정규화: 데이터의 범위를 0부터 1까지로 변환하여 데이터 분포를 조정

![](https://github.com/bird-one-00/25-1_STATISTICS_Assignment/blob/main/img/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202025-02-10%20180201.png)

![](https://github.com/bird-one-00/25-1_STATISTICS_Assignment/blob/main/img/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202025-02-10%20180208.png)

- 그래프를 보면 기존에는 달라보이던 변수 X1과 X2가 변환 후 매우 유사한 모습을 보이는 것을 알 수 있음

3. RobustScaler: 이상치에 민감하다는 표준화, 정규화 방식을 보완한 스케일링 기법. 중앙값(Q2)를 0으로 잡고, Q1과 Q3 사분위수와의 IQR 차이를 1이 되도록 하는 스케일링 기법. 이상치의 영향력을 최소화하여 일반적으로 표준화, 정규화보다 성능이 우수함

## 11.5. 모델 성능 향상을 위한 파생 변수 생성
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요. -->

- 파생 변수: 원래 있던 변수들을 조합하거나 함수를 적용하여 새로 만들어낸 변수
- 파생 변수는 데이터의 특성을 이용하여 분석 효율을 높이는 것이기 때문에 전체 데이터에 대한 파악이 중요할 뿐만 아니라 해당 비즈니스 도메인에 대한 충분한 이해가 수반되어야 함

![](https://github.com/bird-one-00/25-1_STATISTICS_Assignment/blob/main/img/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202025-02-10%20180942.png)

![](https://github.com/bird-one-00/25-1_STATISTICS_Assignment/blob/main/img/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202025-02-10%20180950.png)

- 파생 변수 생성 시 유의할 점: 파생변수는 기존의 변수를 활용해서 만들어낸 변수이기 때문에 **다중공선성** 문제가 발생할 가능성이 높음. 따라서 파생 변수를 만든 다음에는 상관분석을 통해 변수 간의 상관성을 확인할 필요가 있음. 상관성에 따라 파생변수를 사용할 지 여부를 결정할 수 있음



<br>
<br>

# 확인 문제

## 문제 1. 데이터 전처리

> **🧚 한 금융회사의 대출 데이터에서 `소득` 변수에 결측치가 포함되어 있다. 다음 중 가장 적절한 결측치 처리 방법은 무엇인가?**

> **[보기]   
1️⃣ 결측값이 포함된 행을 모두 제거한다.  
2️⃣ 결측값을 `소득` 변수의 평균값으로 대체한다.  
3️⃣ `연령`과 `직업군`을 독립변수로 사용하여 회귀 모델을 만들어 `소득` 값을 예측한다.  
4️⃣ 결측값을 보간법을 이용해 채운다.**

> **[데이터 특징]**     
    - `소득` 변수는 연속형 변수이다.  
    - 소득과 `연령`, `직업군` 간에 강한 상관관계가 있다.  
    - 데이터셋에서 `소득` 변수의 결측 비율은 15%이다.

```
3️⃣번
결측값이 비무작위적으로 발생했을 가능성(NMAR)이 있음
결측치가 10%를 넘고, 소득 변수가 연속형이며, 연령, 직업군 간의 강한 상관관계가 있으므로,
회귀 대치법을 사용하는 것이 가장 적절함
```

## 문제 2. 데이터 스케일링

> **🧚 머신러닝 모델을 학습하는 과정에서, `연봉(단위: 원)`과 `근속연수(단위: 년)`를 동시에 독립변수로 사용해야 합니다. 연봉과 근속연수를 같은 스케일로 맞추기 위해 어떤 스케일링 기법을 적용하는 것이 더 적절한가요?**

<!--표준화와 정규화의 차이점에 대해 고민해보세요.-->

```
표준화(Z-score)가 적절할 것임

연봉과 근속연수는 모두 연속형 변수이지만,
서로 다른 단위를 사용하고 있으므로 평균을 0, 표준편차를 1로 설정하면 서로 비교하기 용이할 것임
```

### 🎉 수고하셨습니다.